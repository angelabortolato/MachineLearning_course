{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning LAB 1: MODEL SELECTION\n",
    "\n",
    "Course 2024/25: *F. Chiariotti*\n",
    "\n",
    "The notebook contains a simple learning task over which we will implement **MODEL SELECTION AND VALIDATION**.\n",
    "\n",
    "Complete all the **required code sections** and **answer all the questions**.\n",
    "\n",
    "### IMPORTANT for the exam:\n",
    "\n",
    "The functions you might be required to implement in the exam will have the same signature and parameters as the ones in the labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial Classification on Signal to Noise Ratios\n",
    "\n",
    "In this notebook we are going to explore the use of polynomial classification with polynomial regression. We are going to use the Numpy **polyfit** function, which performs polynomial regression.\n",
    "\n",
    "Our use case is a communication problem: we have a set of measurements of the Signal to Noise Ratio (SNR), i.e., the quality of the communication link, in various positions. The SNR depends on two components: firstly, the noise level (which is a random variable that does not depend on position) and the signal attenuation (usually modeled as a polynomial function of the distance).\n",
    "\n",
    "Our transmitter is in (0,0), and coordinates are in meters. In urban scenarios, the attenuation usually follows a third-degree polynomial, but it might be a fourth- or fifth-degree polynomial in more complex cases. How do we choose between different degrees? We will try with a maximum of **6**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the necessary Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import itertools\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "In this case, x and y are the two coordinates, and the SNR is the thing we are trying to predict\n",
    "\n",
    "**DO NOT CHANGE THE PRE-WRITTEN CODE UNLESS OTHERWISE SPECIFIED**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/snr_measurements.csv',sep=';')\n",
    "x = df['x'].values    #convert pandas dataframe to numpy arrays\n",
    "y = df['y'].values\n",
    "SNR = df['SNR'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "These functions will help us evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distance(x, y):\n",
    "    distance=(x**2+y**2)**(1/2)\n",
    "    return distance\n",
    "\n",
    "def fit(distance, SNR, degree):\n",
    "    return np.polyfit(distance, SNR, deg=degree)     #is an array of degree+1 elements\n",
    "\n",
    "def predict(distance, poly_coeffs, degree):\n",
    "    # Predict the SNR from a given model\n",
    "    SNR=sum([poly_coeffs[degree-deg]* distance**deg for deg in range(degree+1)])\n",
    "    return SNR      #is an array of predicted SNR\n",
    "\n",
    "def evaluate(distance, SNR, poly_coeffs, degree):\n",
    "    # Compute the error of the polynomial fit on the chosen data with mean square error\n",
    "    mse=(predict(distance, poly_coeffs, degree)-SNR)**2\n",
    "    MSE=sum(mse)\n",
    "    return MSE\n",
    "\n",
    "def separate_test(distance, SNR, test_points):\n",
    "    # Return a training set and a test set (the test_points parameter controls the number of test points).\n",
    "    # The points should be selected randomly, so i first create an array of random indices of size test_points\n",
    "    randindex=np.random.randint(len(distance)+1, size=test_points)    #REPETITION\n",
    "    distance_test=[distance[i] for i in randindex]\n",
    "    SRN_test=[SRN[i] for i in randindex]\n",
    "    for i in range(len(distance)+1):\n",
    "        \n",
    "    return distance_train, SNR_train, distance_test, SNR_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "179.0837472342914\n"
     ]
    }
   ],
   "source": [
    "distance=compute_distance(x,y)\n",
    "\n",
    "degree=8\n",
    "\n",
    "\n",
    "\n",
    "p=fit(distance, SNR, degree)     \n",
    "predictval=predict(distance, p, degree)\n",
    "MSE=evaluate(distance, SNR, p, degree)\n",
    "print(MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: separate the training and test sets and create a scatter plot of the SNR as a function of the distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. K-fold cross-validation\n",
    "\n",
    "In this case, x and y are the two coordinates, and the SNR is the thing we are trying to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform the K-fold cross validation\n",
    "def k_fold_cross_validation(x_train: np.ndarray, y_train: np.ndarray, k: int, max_degree: int) -> tuple[tuple, tuple]:\n",
    "    # TODO: Perform K-fold cross-validation on the training set.\n",
    "    # The two returned values are the best model and the list of results for all degrees up to max_degree.\n",
    "    # The points should be selected randomly.\n",
    "    # The inputs and labels are already in terms of distance and SNR\n",
    "    return best, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run the training with K-fold cross-validation with 40 test points and 4 folds Plot the validation score as a function of the degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get the test performance of the best model and plot the model output and test points. \n",
    "# Try running the program multiple times, changing the values of K and the number of test points: is the output always the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Tikhonov regularization\n",
    "\n",
    "Change the loss function to include a Tikhonov regularization term, as an alternative to cross-validation (try $\\lambda=1$) THIS GETS VERY STRONG REGULARIZATION, TRY $\\lambda=0.01$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_tikhonov(x_train: np.ndarray, y_train: np.ndarray, lambda_par: float, max_degree: int) -> tuple[tuple, tuple]:\n",
    "    # TODO: apply Tikhonov regularization AFTER the fitting process\n",
    "\n",
    "    return best, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run the training with Tikhonov regularization and plot the loss as a function of the degree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Minimum description length regularization\n",
    "\n",
    "Change the loss function to include a representation length regularization term, as an alternative to cross-validation. The minimum description length of a polynomial of degree N is O(2^N) - try $\\lambda=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_representation(x_train: np.ndarray, y_train: np.ndarray, lambda_par: float, max_degree: int) -> tuple[tuple, tuple]:\n",
    "    # TODO: apply Tikhonov regularization AFTER the fitting process\n",
    "\n",
    "    return best, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: run the training with MDL regularization and plot the loss as a function of the degree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST\n",
    "\n",
    "Check the performance of the three solutions on the test set: which one does best?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: plot the results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
