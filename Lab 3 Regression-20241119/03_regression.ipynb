{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning LAB 3: LINEAR REGRESSION\n",
    "\n",
    "Course 2024/25: *F. Chiariotti*\n",
    "\n",
    "The notebook contains some simple tasks to be performed with **LINEAR REGRESSION MODELS**.\n",
    "\n",
    "Complete all the **required code sections**.\n",
    "\n",
    "### IMPORTANT for the exam:\n",
    "\n",
    "The functions you might be required to implement in the exam will have the same signature and parameters as the ones in the labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VR traffic prediction\n",
    "\n",
    "In this notebook, we will explore the prediction of Virtual Reality (VR) traffic. The data come from the paper:\n",
    "\n",
    "Lecci, Mattia, _et al._ \"An open framework for analyzing and modeling XR network traffic.\" IEEE Access 9 (2021): 129782-129795.\n",
    "\n",
    "The VR game Virus Popper was instantiated on a computer through the RiftCat application: the user could then see the virtual content on their phone, which was strapped to their head with a Cardboard viewer. The file virus_popper.csv contains three columns from the traffic capture:\n",
    "idx    | frame size (B) |  time (s)\n",
    "0      | 38424          |  0.0\n",
    "1      | 39801          |  0.01944\n",
    "...\n",
    "\n",
    "The game was run at 60 frames per second, with a target rate of 30 Mb/s. The task is then to predict the size of the next frame, given the past N frames. This was explored in another paper:\n",
    "\n",
    "Chiariotti, Federico, _et al._ \"Temporal characterization and prediction of vr traffic: A network slicing use case.\" IEEE Transactions on Mobile Computing 23.5 (2023): 3890-3908.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the necessary Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as rnd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "def load_dataset(filename):\n",
    "    data_train = pd.read_csv(filename)\n",
    "    data = data_train.iloc[:, 1].values # Get the second column (frame size) as the input\n",
    "    return data\n",
    "\n",
    "# Load the dataset\n",
    "data = load_dataset('data/virus_popper.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data and create training and test sets\n",
    "\n",
    "In this case, we are learning a time series: let us consider a memory of 2 samples, i.e., use X[n-1] and X[n-2] to predict X[n]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25878, 3) (25878,) (8625, 3) (8625,)\n"
     ]
    }
   ],
   "source": [
    "# Normalize the dataset\n",
    "avg_size = np.mean(data)\n",
    "norm_data = np.asarray(data) / avg_size\n",
    "\n",
    "# Compute the splits and prepare the columns\n",
    "m_training = int(0.75*norm_data.shape[0])\n",
    "\n",
    "X_training = np.ones([m_training - 2, 3])\n",
    "X_training[:,1] = norm_data[: m_training - 2]\n",
    "X_training[:,2] = norm_data[1 : m_training - 1]   #X has coordinates 1 (homogeneous repr), X[n-2], X[n-2]\n",
    "Y_training = norm_data[2 : m_training]            #Y has the value we want to predict X[n]\n",
    "\n",
    "\n",
    "X_test = np.ones([norm_data.shape[0] - m_training - 2, 3])\n",
    "X_test[:,1] = norm_data[m_training : -2]\n",
    "X_test[:,2] = norm_data[m_training + 1 : -1]\n",
    "Y_test = norm_data[m_training + 2:]\n",
    "\n",
    "print(np.shape(X_training), np.shape(Y_training), np.shape(X_test), np.shape(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.62896851 0.627468  ]\n"
     ]
    }
   ],
   "source": [
    "print(X_training[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares linear regression\n",
    "\n",
    "Train and evaluate the LS regressor on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Least squares solution\n",
    "def least_squares(X_matrix: np.ndarray, labels: np.ndarray):\n",
    "    ## Run the LS algorithm without regularization\n",
    "    A=np.dot(X_matrix.T, X_matrix)\n",
    "    b=np.dot(X_matrix.T, labels)\n",
    "    return np.matmul(np.linalg.inv(A), b)\n",
    "\n",
    "def evaluate_model(x, y, coeff):\n",
    "    ## Return the average MSE for the set over which we evaluate\n",
    "    mse=(np.dot(x, coeff) - y)**2\n",
    "    MSE=sum(mse)\n",
    "    return MSE/len(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model coefficients: [0.36986742 0.20348677 0.42565451]\n",
      "MSE:  0.015483932733208724 Root MSE: 7712.354721539206\n"
     ]
    }
   ],
   "source": [
    "# Run the LS training and test it on the test data\n",
    "trained_model = least_squares(X_training, Y_training)\n",
    "mse = evaluate_model(X_test, Y_test, trained_model)\n",
    "print('Model coefficients:', trained_model)\n",
    "print('MSE: ', mse, 'Root MSE:', np.sqrt(mse) * avg_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Least Squares with Tikhonov regularization\n",
    "\n",
    "Perform K-fold cross validation with $\\lambda\\in\\{0, 0.1, 1, 10\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-23-f3f6c356f338>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-f3f6c356f338>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    ## TODO: Perform K-fold cross-validation\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# Least squares solution\n",
    "def regularized_least_squares(X_matrix: np.ndarray, labels: np.ndarray, lambda_par: np.ndarray) -> None:\n",
    "    ## Run the LS algorithm with regularization\n",
    "    A=np.dot(X_matrix.T, X_matrix)\n",
    "    b=np.dot(X_matrix.T, labels)\n",
    "    return np.matmul(np.linalg.inv(2*lambda_par*np.eye(A.shape[0])+A), b)\n",
    "\n",
    "def K_fold(X_training: np.ndarray, Y_training: np.ndarray, lambda_vec: np.ndarray, K: np.ndarray) -> None:\n",
    "    ## TODO: Perform K-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training with K-fold cross-validation and plot the score\n",
    "K = 5\n",
    "lambda_par = range(21)\n",
    "\n",
    "best_model, best_perf, models, results = K_fold(X_training, Y_training, lambda_par, K)\n",
    "print(best_model, results)\n",
    "plt.plot(lambda_par, np.sqrt(results) * avg_size)\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for the regularized models on the test set\n",
    "test_scores = np.zeros(len(models))\n",
    "\n",
    "for i in range(len(models)):\n",
    "    test_scores[i] = evaluate_model(X_test, Y_test, models[i])\n",
    "\n",
    "plt.plot(lambda_par, np.sqrt(test_scores) * avg_size)\n",
    "plt.xlabel('$\\lambda$')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXTRA\n",
    "\n",
    "Can you figure out the best amount of memory to use?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
