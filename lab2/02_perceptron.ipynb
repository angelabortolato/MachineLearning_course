{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning LAB 2: Perceptrons\n",
    "\n",
    "Course 2024/25: *F. Chiariotti*\n",
    "\n",
    "The notebook contains a simple learning task over which we will implement **MODEL SELECTION AND VALIDATION**.\n",
    "\n",
    "Complete all the **required code sections** and **answer all the questions**.\n",
    "\n",
    "### IMPORTANT for the exam:\n",
    "\n",
    "The functions you might be required to implement in the exam will have the same signature and parameters as the ones in the labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification of Stayed/Churned Customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Customer Churn table contains information on all 3,758 customers from a Telecommunications company in California in Q2 2022. Companies are naturally interested in churn, i.e., in which users are likely to switch to another company soon to get a better deal, and which are more loyal customers.\n",
    "\n",
    "The dataset contains three features:\n",
    "- **Tenure in Months**: Number of months the customer has stayed with the company\n",
    "- **Monthly Charge**: The amount charged to the customer monthly\n",
    "- **Age**: Customer's age\n",
    "\n",
    "The aim of the task is to predict if a customer will churn or not based on the three features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all the necessary Python libraries and load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Dataset\n",
    "The dataset is a `.csv` file containing three input features and a label. Here is an example of the first 4 rows of the dataset: \n",
    "\n",
    "<center>\n",
    "\n",
    "Tenure in Months | Monthly Charge | Age | Customer Status |\n",
    "| -----------------| ---------------|-----|-----------------|\n",
    "| 9 | 65.6 | 37 | 0 |\n",
    "| 9 | -4.0 | 46 | 0 |\n",
    "| 4 | 73.9 | 50 | 1 |\n",
    "| ... | ... | ... | ... |\n",
    "\n",
    "</center>\n",
    "\n",
    "Customer Status is 0 if the customer has stayed with the company and 1 if the customer has churned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rnd\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import linear_model, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "def load_dataset(filename):\n",
    "    data_train = pd.read_csv(filename)\n",
    "    #permute the data\n",
    "    data_train = data_train.sample(frac=1).reset_index(drop=True) # shuffle the data\n",
    "    X = data_train.iloc[:, 0:3].values # Get first two columns as the input\n",
    "    Y = data_train.iloc[:, 3].values # Get the third column as the label\n",
    "    Y = 2*Y-1 # Make sure labels are -1 or 1 (0 --> -1, 1 --> 1)\n",
    "    return X,Y\n",
    "\n",
    "# Load the dataset\n",
    "X, Y = load_dataset('data/telecom_customer_churn_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to differentiate (classify) between **class \"1\" (churned)** and **class \"-1\" (stayed)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in the train set: 2817\n",
      "Number of samples in the test set: 940\n",
      "Number of churned users in test: 465\n",
      "Number of loyal users in test: 475\n",
      "Mean of the training input data: [ 0. -0. -0.]\n",
      "Std of the training input data: [1. 1. 1.]\n",
      "Mean of the test input data: [ 0.0134851   0.04850383 -0.0433016 ]\n",
      "Std of the test input data: [1.00014294 1.00683022 1.02078989]\n"
     ]
    }
   ],
   "source": [
    "# Compute the splits\n",
    "m_training = int(0.75*X.shape[0])\n",
    "\n",
    "# m_test is the number of samples in the test set (total-training)\n",
    "m_test =  X.shape[0] - m_training\n",
    "X_training =  X[:m_training]\n",
    "Y_training =  Y[:m_training]\n",
    "X_test =   X[m_training:]\n",
    "Y_test =  Y[m_training:]\n",
    "\n",
    "print(\"Number of samples in the train set:\", X_training.shape[0])\n",
    "print(\"Number of samples in the test set:\", X_test.shape[0])\n",
    "print(\"Number of churned users in test:\", np.sum(Y_test==-1))\n",
    "print(\"Number of loyal users in test:\", np.sum(Y_test==1))\n",
    "\n",
    "# Standardize the input matrix\n",
    "# The transformation is computed on training data and then used on all the 3 sets\n",
    "scaler = preprocessing.StandardScaler().fit(X_training) \n",
    "\n",
    "np.set_printoptions(suppress=True) # sets to zero floating point numbers < min_float_eps\n",
    "X_training =  scaler.transform(X_training)\n",
    "print (\"Mean of the training input data:\", X_training.mean(axis=0))\n",
    "print (\"Std of the training input data:\",X_training.std(axis=0))\n",
    "\n",
    "X_test =  scaler.transform(X_test)\n",
    "print (\"Mean of the test input data:\", X_test.mean(axis=0))\n",
    "print (\"Std of the test input data:\", X_test.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use **homogeneous coordinates** to describe all the coefficients of the model.\n",
    "\n",
    "_Hint:_ The conversion can be performed with the function $hstack$ in $numpy$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_homogeneous(X_training, X_test):\n",
    "    # Transform the input into homogeneous coordinates\n",
    "    b_training=np.ones((X_training.shape[0],1))\n",
    "    b_test=np.ones((X_test.shape[0],1))\n",
    "    Xh_training = np.hstack((b_training,X_training))\n",
    "    Xh_test= np.hstack((b_test,X_test))\n",
    "    return Xh_training, Xh_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set in homogeneous coordinates:\n",
      "[[ 1.          1.2361321   0.87798477 -0.16001986]\n",
      " [ 1.          0.10884685  0.4417593   1.37363294]\n",
      " [ 1.          1.69539647 -1.57223186 -0.04204657]\n",
      " [ 1.          0.15059816 -0.93544295  0.84275312]\n",
      " [ 1.          0.56811122 -0.38890759 -0.57292638]\n",
      " [ 1.         -0.39216881 -1.41010975 -0.39596645]\n",
      " [ 1.         -1.0184384  -1.53880462 -1.04481955]\n",
      " [ 1.         -0.35041751 -0.71649454  0.72477983]\n",
      " [ 1.         -1.18544362 -1.45857925  0.4298466 ]\n",
      " [ 1.          1.44488863 -1.4385229  -0.16001986]]\n"
     ]
    }
   ],
   "source": [
    "# convert to homogeneous coordinates using the function above\n",
    "X_training, X_test = to_homogeneous(X_training, X_test)\n",
    "print(\"Training set in homogeneous coordinates:\")\n",
    "print(X_training[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deterministic perceptron\n",
    "\n",
    "Now **complete** the function *perceptron*. <br>\n",
    "The **perceptron** algorithm **does not terminate** if the **data** is not **linearly separable**, therefore your implementation should **terminate** if it **reached the termination** condition seen in class **or** if a **maximum number of iterations** have already been run, where one **iteration** corresponds to **one update of the perceptron weights**. In case the **termination** is reached **because** the **maximum** number of **iterations** have been completed, the implementation should **return the best model** seen throughout.\n",
    "\n",
    "The current version of the perceptron is **deterministic**: we use a fixed rule to decide which sample should be considered (e.g., the one with the lowest index).\n",
    "\n",
    "The input parameters to pass are:\n",
    "- $X$: the matrix of input features, one row for each sample\n",
    "- $Y$: the vector of labels for the input features matrix X\n",
    "- $max\\_num\\_iterations$: the maximum number of iterations for running the perceptron\n",
    "\n",
    "The output values are:\n",
    "- $best\\_w$: the vector with the coefficients of the best model (or the latest, if the termination condition is reached)\n",
    "- $best\\_error$: the *fraction* of misclassified samples for the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_errors(current_w, X, Y):\n",
    "    # This function:\n",
    "    # -computes the number of misclassified samples\n",
    "    n=0\n",
    "    # -returns the indexes of all misclassified samples \n",
    "    index=[]\n",
    "    # -if there are no misclassified samples, returns -1 as index \n",
    "    for idx in range(X.shape[0]):\n",
    "        if Y[idx]*(np.inner(current_w,X[idx, :]))<=0 :\n",
    "            n+=1\n",
    "            index.append(idx)\n",
    "            if n==0:\n",
    "                index=-1\n",
    "    return n, index\n",
    "\n",
    "    \n",
    "def perceptron_fixed_update(current_w, X, Y):\n",
    "# perceptron update function\n",
    "    n, index =count_errors(current_w, X, Y)\n",
    "    if n==0 :\n",
    "        new_w=current_w \n",
    "    else : \n",
    "        new_w= current_w + Y[index[0]]*X[index[0], :] \n",
    "    return new_w \n",
    "    \n",
    "def perceptron_no_randomization(X, Y, max_num_iterations): \n",
    "    # write the perceptron main loop \n",
    "    current_w=np.zeros((X.shape[1])) \n",
    "    (n,index)=count_errors(current_w, X, Y)\n",
    "    best_w=current_w\n",
    "    best_error=n/X.shape[0]\n",
    "    iters=0\n",
    "    while n!=0 and iters < max_num_iterations: \n",
    "        current_w=perceptron_fixed_update(current_w, X, Y)\n",
    "        n, index = count_errors(current_w, X, Y)\n",
    "        if n/X.shape[0] < best_error:\n",
    "            best_error=n/X.shape[0]\n",
    "            best_w=current_w\n",
    "        iters+=1\n",
    "    # The perceptron should run for up to max_num_iterations, or stop if it finds a solution with ERM=0\n",
    "    return best_w, best_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the implementation above of the perceptron to learn a model from the training data using 30 iterations and print the error of the best model we have found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error of perceptron (30 iterations): 0.24565140220092296\n",
      "Training Error of perceptron (100 iterations): 0.24565140220092296\n"
     ]
    }
   ],
   "source": [
    "w_found, error = perceptron_no_randomization(X_training,Y_training, 30)\n",
    "print(\"Training Error of perceptron (30 iterations): \" + str(error))\n",
    "w_found2, error2 = perceptron_no_randomization(X_training,Y_training, 100)\n",
    "print(\"Training Error of perceptron (100 iterations): \" + str(error2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the best model $w\\_found$ to **predict the labels for the test dataset** and print the fraction of misclassified samples in the test set (the test error that is an estimate of the true loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error of perceptron (30 iterations): 0.25\n",
      "Test Error of perceptron (100 iterations): 0.25\n"
     ]
    }
   ],
   "source": [
    "def loss_estimate(w,X,Y):\n",
    "    n_err, i = count_errors(w, X, Y)\n",
    "    t_loss_estimate= n_err/len(Y)\n",
    "    return t_loss_estimate\n",
    "\n",
    "\n",
    "true_loss_estimate =  loss_estimate(w_found, X_test, Y_test)       # Error rate on the test set\n",
    "true_loss_estimate2 =  loss_estimate(w_found2, X_test, Y_test) \n",
    "    \n",
    "print(\"Test Error of perceptron (30 iterations): \" + str(true_loss_estimate))\n",
    "print(\"Test Error of perceptron (100 iterations): \" + str(true_loss_estimate2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized perceptron\n",
    "\n",
    "Implement the correct randomized version of the perceptron such that at each iteration the algorithm picks a random misclassified sample and updates the weights using that sample. The functions will be very similar, except for some minor details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_randomized_update(current_w, X, Y):\n",
    "    n, index =count_errors(current_w, X, Y)\n",
    "    if n==0 :\n",
    "        new_w=current_w \n",
    "    else : \n",
    "        i=rnd.choice(index)\n",
    "        new_w= current_w + Y[i]*X[i, :] \n",
    "    return new_w \n",
    "\n",
    "def perceptron_with_randomization(X, Y, max_num_iterations):\n",
    "    current_w=np.zeros((X.shape[1])) \n",
    "    (n,index)=count_errors(current_w, X, Y)\n",
    "    best_w=current_w\n",
    "    best_error=n/X.shape[0]\n",
    "    iters=0\n",
    "    while n!=0 and iters < max_num_iterations: \n",
    "        current_w=perceptron_randomized_update(current_w, X, Y)\n",
    "        n, index = count_errors(current_w, X, Y)\n",
    "        if n/X.shape[0] < best_error:\n",
    "            best_error=n/X.shape[0]\n",
    "            best_w=current_w\n",
    "        iters+=1\n",
    "    # The perceptron should run for up to max_num_iterations, or stop if it finds a solution with ERM=0\n",
    "    return best_w, best_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the correct version of the perceptron using 30 iterations and print the error of the best model we have found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error of perceptron (30 iterations): 0.25168619098331557\n",
      "Training Error of perceptron (100 iterations): 0.24813631522896698\n",
      "Test Error of perceptron (30 iterations): 0.25638297872340426\n",
      "Test Error of perceptron (100 iterations): 0.2680851063829787\n"
     ]
    }
   ],
   "source": [
    "# Now run the perceptron for 30 iterations\n",
    "w_found, error = perceptron_with_randomization(X_training, Y_training, 30)\n",
    "w_found2, error2 = perceptron_with_randomization(X_training, Y_training, 100)\n",
    "print(\"Training Error of perceptron (30 iterations): \" + str(error))\n",
    "print(\"Training Error of perceptron (100 iterations): \" + str(error2))\n",
    "\n",
    "true_loss_estimate =  loss_estimate(w_found, X_test, Y_test)       # Error rate on the test set\n",
    "true_loss_estimate2 =  loss_estimate(w_found2, X_test, Y_test) \n",
    "\n",
    "print(\"Test Error of perceptron (30 iterations): \" + str(true_loss_estimate))\n",
    "print(\"Test Error of perceptron (100 iterations): \" + str(true_loss_estimate2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss with respect to the number of iterations (up to 1000)\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "num_iters = np.arange(0, 1001,200)\n",
    "errors_rand = []\n",
    "errors_det = []\n",
    "\n",
    "for num_iter in num_iters:\n",
    "    _, error_rand = perceptron_with_randomization(X_training, Y_training, num_iter)\n",
    "    _, error_det = perceptron_no_randomization(X_training, Y_training, num_iter)\n",
    "    errors_rand.append(error_rand)\n",
    "    errors_det.append(error_det)\n",
    "\n",
    "plt.plot(num_iters, errors_rand, label='Random')\n",
    "plt.plot(num_iters, errors_det, label='Deterministic')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Training error')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
